{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Question 1","metadata":{}},{"cell_type":"markdown","source":"### Data","metadata":{}},{"cell_type":"markdown","source":"We represent an estimation of the grade of one student for an oral presentation.\n\nX ∈ {1, 30} is the variable representing the choosen student. Y ∈ {1, 5} is the variable representing the grade of the participant.\n\nWe assume that :\n- X is uniformly distributed.\n- l is the 0− 1 loss (1 if there is a mistake, 0 otherwise)\n- The random variable with the following distribution (knowing the severity of the professor and the previous score of the students of this class):\n    - P(Y=1∣X=x)=0.15\n    - P(Y=2∣X=x)=0.25\n    - P(Y=3∣X=x)=0.35\n    - P(Y=4∣X=x)=0.15\n    - P(Y=5∣X=x)=0.1\n\n","metadata":{}},{"cell_type":"markdown","source":"### Bayes predictor","metadata":{}},{"cell_type":"markdown","source":"$f^∗(x) = arg min_{z∈Y}~E[l(Y, z)|X = x] \\\\\n ~~~~~~~~~= arg_{z∈Y}min~P(Y ̸= z|X = x)~because~l~is~the~0-1~loss \\\\\n ~~~~~~~~~= arg_{z∈Y}min~1− P(Y = z|X = x) \\\\\n ~~~~~~~~~= arg_{z∈Y}max~P(Y = z|X = x)$\n \nWe have :\n - P(Y=1∣X=x)=0.15\n - P(Y=2∣X=x)=0.25\n - P(Y=3∣X=x)=0.35\n - P(Y=4∣X=x)=0.15\n - P(Y=5∣X=x)=0.1\n \nSo $f^∗(x) = 3$ pour tout X","metadata":{}},{"cell_type":"markdown","source":"### Bayes Risk","metadata":{}},{"cell_type":"markdown","source":"$R^*(f^*)=E[l(Y,f^*(x))] \\\\\n~~~~~~~~~~~~=0 * P(Y = f^*(X)) + 1 * P(Y ≠ f^*(X)) \\\\\n~~~~~~~~~~~~= P(Y ≠ f^*(X)) \\\\\n~~~~~~~~~~~~= P(Y ≠ f^*(X))∩(X = 1)) +...+P(Y ≠ f^*(X))∩(X = 30)) \\\\\n~~~~~~~~~~~~= P ((Y ≠ f^*(X))|X = 1)P(X = 1) +....+ P((Y ≠ f^*(X))|X = 30)P(X = 30)$\n\nOn a:\n$P(Y ≠ f^*(X))∩(X = 1))=P(Y ≠ f^*(X))) = 1 - P(Y=3) \\\\$\net\n$P(X=1)=...=P(X=30) = 1/30$ car X suit une loi uniforme\n\nDonc $R^*(f^*)=30* 1/30 * (1-0.35) \\\\\n~~~~~~~~~~~~= 0.65$","metadata":{}},{"cell_type":"markdown","source":"# Question 2","metadata":{}},{"cell_type":"code","source":"import numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-06-27T12:50:52.632615Z","iopub.execute_input":"2024-06-27T12:50:52.632997Z","iopub.status.idle":"2024-06-27T12:50:52.637707Z","shell.execute_reply.started":"2024-06-27T12:50:52.632967Z","shell.execute_reply":"2024-06-27T12:50:52.636611Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def generate_data(n_samples):\n    X = np.random.randint(1, 31, n_samples)\n    #the +1 is necessary because values are generated between 0 and 4 and we want them between 1 and 5\n    Y = np.random.choice(5, n_samples, p=[0.15, 0.25, 0.35, 0.15, 0.1]) + 1\n    return X, Y\n\n# Generate a test set\nn_test = 100000\nX_test, Y_test = generate_data(n_test)\n\n# Compute empirical risk for Bayes estimator\nY_pred_bayes = np.full(n_test, 3)\nempirical_risk_bayes = len(np.where(Y_test != Y_pred_bayes)[0]) / n_test\n\n# Compute empirical risk for bad estimator\nY_pred_proposed = np.full(n_test, 2)  #We choose 2 for the bad estimator\nempirical_risk_proposed = len(np.where(Y_test != Y_pred_proposed)[0]) / n_test\n\nprint(f\"Test error for Bayes estimator: {empirical_risk_bayes:.4f}\")\nprint(f\"Test error for proposed estimator: {empirical_risk_proposed:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-27T12:55:16.282493Z","iopub.execute_input":"2024-06-27T12:55:16.282913Z","iopub.status.idle":"2024-06-27T12:55:16.296664Z","shell.execute_reply.started":"2024-06-27T12:55:16.282879Z","shell.execute_reply":"2024-06-27T12:55:16.295469Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Test error for Bayes estimator: 0.6514\nTest error for proposed estimator: 0.7499\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The generalization error is smaller for $f^∗(x)$ than for the estimator f(x) = 2 (0.6514 < 0.7499).\n\nThe test error for $f^*$ is 0.6514, which is pretty close of the bayes risk (0.65) for a large number od data.","metadata":{}}]}